{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NGk9LiTM0SvQ",
        "outputId": "47f0041f-d35c-4a3c-d328-1576766399c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting langchain-huggingface\n",
            "  Downloading langchain_huggingface-1.1.0-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting huggingface-hub<1.0.0,>=0.33.4 (from langchain-huggingface)\n",
            "  Downloading huggingface_hub-0.36.0-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=1.1.0 in d:\\genaideepdive-batch15\\venv\\lib\\site-packages (from langchain-huggingface) (1.1.0)\n",
            "Collecting tokenizers<1.0.0,>=0.19.1 (from langchain-huggingface)\n",
            "  Using cached tokenizers-0.22.1-cp39-abi3-win_amd64.whl.metadata (6.9 kB)\n",
            "Collecting filelock (from huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface)\n",
            "  Using cached filelock-3.20.0-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting fsspec>=2023.5.0 (from huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface)\n",
            "  Downloading fsspec-2025.12.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: packaging>=20.9 in d:\\genaideepdive-batch15\\venv\\lib\\site-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in d:\\genaideepdive-batch15\\venv\\lib\\site-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (6.0.3)\n",
            "Requirement already satisfied: requests in d:\\genaideepdive-batch15\\venv\\lib\\site-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (2.32.5)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in d:\\genaideepdive-batch15\\venv\\lib\\site-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in d:\\genaideepdive-batch15\\venv\\lib\\site-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (4.15.0)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in d:\\genaideepdive-batch15\\venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.1.0->langchain-huggingface) (1.33)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in d:\\genaideepdive-batch15\\venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.1.0->langchain-huggingface) (0.4.46)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in d:\\genaideepdive-batch15\\venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.1.0->langchain-huggingface) (2.12.4)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in d:\\genaideepdive-batch15\\venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.1.0->langchain-huggingface) (9.1.2)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in d:\\genaideepdive-batch15\\venv\\lib\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.1.0->langchain-huggingface) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in d:\\genaideepdive-batch15\\venv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain-huggingface) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in d:\\genaideepdive-batch15\\venv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain-huggingface) (3.11.4)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in d:\\genaideepdive-batch15\\venv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain-huggingface) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in d:\\genaideepdive-batch15\\venv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain-huggingface) (0.25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in d:\\genaideepdive-batch15\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.1.0->langchain-huggingface) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.5 in d:\\genaideepdive-batch15\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.1.0->langchain-huggingface) (2.41.5)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in d:\\genaideepdive-batch15\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.1.0->langchain-huggingface) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in d:\\genaideepdive-batch15\\venv\\lib\\site-packages (from requests->huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in d:\\genaideepdive-batch15\\venv\\lib\\site-packages (from requests->huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\genaideepdive-batch15\\venv\\lib\\site-packages (from requests->huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in d:\\genaideepdive-batch15\\venv\\lib\\site-packages (from requests->huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (2025.11.12)\n",
            "Requirement already satisfied: colorama in d:\\genaideepdive-batch15\\venv\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (0.4.6)\n",
            "Requirement already satisfied: anyio in d:\\genaideepdive-batch15\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain-huggingface) (4.11.0)\n",
            "Requirement already satisfied: httpcore==1.* in d:\\genaideepdive-batch15\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain-huggingface) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in d:\\genaideepdive-batch15\\venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain-huggingface) (0.16.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in d:\\genaideepdive-batch15\\venv\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain-huggingface) (1.3.1)\n",
            "Downloading langchain_huggingface-1.1.0-py3-none-any.whl (29 kB)\n",
            "Downloading huggingface_hub-0.36.0-py3-none-any.whl (566 kB)\n",
            "   ---------------------------------------- 0.0/566.1 kB ? eta -:--:--\n",
            "   ---------------------------------------- 566.1/566.1 kB 4.8 MB/s eta 0:00:00\n",
            "Using cached tokenizers-0.22.1-cp39-abi3-win_amd64.whl (2.7 MB)\n",
            "Downloading fsspec-2025.12.0-py3-none-any.whl (201 kB)\n",
            "Using cached filelock-3.20.0-py3-none-any.whl (16 kB)\n",
            "Installing collected packages: fsspec, filelock, huggingface-hub, tokenizers, langchain-huggingface\n",
            "Successfully installed filelock-3.20.0 fsspec-2025.12.0 huggingface-hub-0.36.0 langchain-huggingface-1.1.0 tokenizers-0.22.1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 24.2 -> 25.3\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "! pip install langchain-huggingface"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "LE6-BPd40uHf"
      },
      "outputs": [],
      "source": [
        "from langchain_huggingface import ChatHuggingFace, HuggingFaceEndpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GpFxaG-o1Siw"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "d:\\GenAIDeepDive-Batch15\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "model = HuggingFaceEndpoint(\n",
        "    repo_id=\"deepseek-ai/DeepSeek-V3.2\",\n",
        "    task=\"text-generation\",\n",
        "    huggingfacehub_api_token=os.getenv(\"HUGGINGFACE_API_TOKEN\")\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "8pEVT7VJ2i3R"
      },
      "outputs": [],
      "source": [
        "chat_model = ChatHuggingFace(llm=model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "iaZpgxOQ3EXo"
      },
      "outputs": [],
      "source": [
        "response = chat_model.invoke(\"Could you help me in writting a blog on Generative AI in 300 words?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bfg-fWrs3MwU",
        "outputId": "bd35b713-df71-4209-b309-9966dd7c349b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "**Demystifying Generative AI: It's More Than Just Hype**\n",
            "\n",
            "You’ve seen the headlines, marveled at the images, and maybe even had a conversation with a chatbot. This is the world of **Generative AI**, and it’s fundamentally shifting how we create and interact with digital content.\n",
            "\n",
            "Unlike traditional AI that analyzes data, Generative AI creates something new. It learns patterns from massive datasets—text, code, images, music—and uses that knowledge to generate original outputs. Ask it for a blog idea, and it provides outlines. Give it a text prompt, and it can write marketing copy, code snippets, or even poetry.\n",
            "\n",
            "The most recognizable tools are **Large Language Models (LLMs)** like ChatGPT, which power conversational assistants and writing aids. But the creativity extends to **visual AI**, generating stunning artwork and realistic photos from simple descriptions, and **audio AI**, composing music or cloning voices.\n",
            "\n",
            "**Why does this matter for you?**\n",
            "\n",
            "The potential is transformative:\n",
            "*   **Boosted Productivity:** Automate first drafts, brainstorm ideas, and summarize complex documents.\n",
            "*   **Hyper-Personalization:** Create tailored marketing content, educational tools, or product designs at scale.\n",
            "*   **Democratized Creativity:** Lower the barrier for content creation, allowing anyone to prototype ideas visually or verbally.\n",
            "\n",
            "However, this power comes with necessary conversations about **ethics, bias, and authenticity**. The outputs are only as good as their training data, and issues of copyright, misinformation, and job displacement are real and pressing.\n",
            "\n",
            "**The Bottom Line:**\n",
            "Generative AI isn’t a magic replacement for human ingenuity; it’s a powerful **collaborative tool**. Its true value lies in augmenting human skills—handling the initial heavy lifting so we can focus on strategy, emotion, nuance, and final polish. The future belongs not to those replaced by AI, but to those who learn to use it wisely as a co-pilot for creativity and efficiency.\n",
            "\n",
            "**Ready to explore? Start with a simple prompt in a free tool and see where it takes your next project.**\n"
          ]
        }
      ],
      "source": [
        "print(response.content)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv (3.12.6)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
